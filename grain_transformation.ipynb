{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn as sklearn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy import stats\n",
    "import statistics as es \n",
    "import csv\n",
    "import re \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENEM  DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose just useful features for us \n",
    "fenem= ['NU_INSCRICAO','CO_ESCOLA','Q001','Q002', 'NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT', 'NU_NOTA_REDACAO']\n",
    "enem17=pd.read_csv(\"~/data/Enem/MICRODADOS_ENEM_2017.csv\", sep=';',encoding=\"iso-8859-2\", usecols = fenem)\n",
    "enem18=pd.read_csv(\"~/data/Enem/MICRODADOS_ENEM_2018.csv\", sep=';',encoding=\"iso-8859-2\", usecols = fenem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#category=(['NU_INSCRICAO','CO_ESCOLA','Q001','Q002'])\n",
    "#enem17[category]= enem17[category].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "enem17 = enem17.copy()\n",
    "enem18 = enem18.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6731341 students of 33834 Schools in ENEM 2017\n",
      "There are 5513747 students of 32253 Schools in ENEM 2018\n"
     ]
    }
   ],
   "source": [
    "#How many Students left? How many schools are they in?\n",
    "print (\"There are\", enem17.shape[0], \"students\",  \"of\", enem17.CO_ESCOLA.value_counts().count() ,\"Schools in ENEM 2017\")\n",
    "#enem17.head()\n",
    "\n",
    "print (\"There are\", enem18.shape[0], \"students\",  \"of\", enem18.CO_ESCOLA.value_counts().count() ,\"Schools in ENEM 2018\")\n",
    "#enem18.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set last quartile of average scores as the best students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first, drop out those whithout schools \n",
    "enem17.dropna(inplace = True, axis=0, subset=['CO_ESCOLA'])\n",
    "enem18.dropna(inplace = True, axis=0, subset=['CO_ESCOLA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second, drop out insufficient scores \n",
    "fields = (['NU_NOTA_CN', 'NU_NOTA_CN','NU_NOTA_CN','NU_NOTA_CN', 'NU_NOTA_REDACAO'])\n",
    "# With NaN\n",
    "enem17.dropna(inplace = True, axis=0, subset=fields)\n",
    "enem18.dropna(inplace = True, axis=0, subset=fields)\n",
    "# With 0\n",
    "enem17 = enem17[~(enem17[fields] == 0).any(axis=1)]\n",
    "enem18 = enem18[~(enem18[fields] == 0).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating average of students in all fields\n",
    "enem17['AVG_SCORE'] = (enem17.NU_NOTA_CN + enem17.NU_NOTA_CH + enem17.NU_NOTA_LC + enem17.NU_NOTA_MT + enem17.NU_NOTA_REDACAO)/5\n",
    "enem18['AVG_SCORE'] = (enem18.NU_NOTA_CN + enem18.NU_NOTA_CH + enem18.NU_NOTA_LC + enem18.NU_NOTA_MT + enem18.NU_NOTA_REDACAO)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the average of all schools by each studentes score\n",
    "enem17['AVG_SCORE_SCHOOL'] = enem17.groupby(['CO_ESCOLA'])['AVG_SCORE'].transform('mean') \n",
    "enem18['AVG_SCORE_SCHOOL'] = enem18.groupby(['CO_ESCOLA'])['AVG_SCORE'].transform('mean') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting out the shcool's scores in quartiles. The upper quartile will be the Good Schools.\n",
    "enem17['TARGET'] = pd.qcut (enem17.AVG_SCORE_SCHOOL, 4, labels = [1,2,3,4]).map(lambda x : 0 if x!=4 else 1) \n",
    "enem18['TARGET'] = pd.qcut (enem18.AVG_SCORE_SCHOOL, 4, labels = [1,2,3,4]).map(lambda x : 0 if x!=4 else 1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.00009542589339 % lowers quartis in ENEM 2017\n",
      "75.00310581817226 % lowers quartis in ENEM 2018\n"
     ]
    }
   ],
   "source": [
    "#It's right? \n",
    "print((enem17.TARGET==0).sum()/(enem17.TARGET.count())*100, '% lowers quartis in ENEM 2017')\n",
    "print((enem18.TARGET==0).sum()/(enem18.TARGET.count())*100, '% lowers quartis in ENEM 2018')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEACHERS CENSUS DATASET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose just useful features for us now, improve memory use\n",
    "fcenso = ['CO_PESSOA_FISICA','NU_ANO_CENSO','IN_ESPECIALIZACAO','IN_MESTRADO','IN_DOUTORADO','CO_ENTIDADE']\n",
    "\n",
    "#Reading data of Teachers in Censo 2017\n",
    "CO17=pd.read_csv(\"~/data/censo2017/DOCENTES_CO.CSV\", sep='|', encoding=\"iso-8859-2\", usecols = fcenso)\n",
    "NE17=pd.read_csv(\"~/data/censo2017/DOCENTES_NORDESTE.CSV\", sep='|', encoding=\"iso-8859-2\", usecols = fcenso)\n",
    "NT17=pd.read_csv(\"~/data/censo2017/DOCENTES_NORTE.CSV\", sep='|', encoding=\"iso-8859-2\", usecols = fcenso)\n",
    "SE17=pd.read_csv(\"~/data/censo2017/DOCENTES_SUDESTE.CSV\", sep='|', encoding=\"iso-8859-2\", usecols = fcenso)\n",
    "SU17=pd.read_csv(\"~/data/censo2017/DOCENTES_SUL.CSV\", sep='|', encoding=\"iso-8859-2\", usecols = fcenso)\n",
    "\n",
    "#There are differences in feature names\n",
    "fcenso18 = ['ID_DOCENTE','NU_ANO_CENSO','IN_ESPECIALIZACAO','IN_MESTRADO','IN_DOUTORADO','CO_ENTIDADE']\n",
    "\n",
    "CO18=pd.read_csv(\"~/data/censo2018/DOCENTES_CO.CSV\", sep='|', encoding=\"iso-8859-2\", usecols = fcenso18)\n",
    "NE18=pd.read_csv(\"~/data/censo2018/DOCENTES_NORDESTE.CSV\", sep='|', encoding=\"iso-8859-2\", usecols = fcenso18)\n",
    "NT18=pd.read_csv(\"~/data/censo2018/DOCENTES_NORTE.CSV\", sep='|', encoding=\"iso-8859-2\", usecols = fcenso18)\n",
    "SE18=pd.read_csv(\"~/data/censo2018/DOCENTES_SUDESTE.CSV\", sep='|', encoding=\"iso-8859-2\", usecols = fcenso18)\n",
    "SU18=pd.read_csv(\"~/data/censo2018/DOCENTES_SUL.CSV\", sep='|', encoding=\"iso-8859-2\", usecols = fcenso18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatening the subsets and creating a unique dataset, than transform all features and categories, as it are.\n",
    "censo17= pd.concat([CO17, NE17, NT17, SE17, SU17])\n",
    "censo17 = censo17.copy()\n",
    "\n",
    "censo18= pd.concat([CO18, NE18, NT18, SE18, SU18])\n",
    "censo18 = censo18.copy()\n",
    "#censo17=censo17.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get only teachers who work in secondary schools (based on ENEM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2603186 Teachers at 185925 Schools in Census 2017\n",
      "There are 2581297 Teachers at 183746 Schools in Census 2018\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NU_ANO_CENSO</th>\n",
       "      <th>CO_PESSOA_FISICA</th>\n",
       "      <th>IN_ESPECIALIZACAO</th>\n",
       "      <th>IN_MESTRADO</th>\n",
       "      <th>IN_DOUTORADO</th>\n",
       "      <th>CO_ENTIDADE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>117579049642</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53056000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>117579049642</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53056000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>117579049642</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53056000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>113802839063</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53008456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>113802839063</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53008456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NU_ANO_CENSO  CO_PESSOA_FISICA  IN_ESPECIALIZACAO  IN_MESTRADO  \\\n",
       "0          2017      117579049642                1.0          0.0   \n",
       "1          2017      117579049642                1.0          0.0   \n",
       "2          2017      117579049642                1.0          0.0   \n",
       "3          2017      113802839063                0.0          0.0   \n",
       "4          2017      113802839063                0.0          0.0   \n",
       "\n",
       "   IN_DOUTORADO  CO_ENTIDADE  \n",
       "0           0.0     53056000  \n",
       "1           0.0     53056000  \n",
       "2           0.0     53056000  \n",
       "3           0.0     53008456  \n",
       "4           0.0     53008456  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Some informations\n",
    "print (\"There are\", censo17.drop_duplicates('CO_PESSOA_FISICA').shape[0], \"Teachers\",  \"at\", censo17.CO_ENTIDADE.value_counts().count() ,\"Schools in Census 2017\")\n",
    "censo17.head()\n",
    "\n",
    "print (\"There are\", censo18.drop_duplicates('ID_DOCENTE').shape[0], \"Teachers\",  \"at\", censo18.CO_ENTIDADE.value_counts().count() ,\"Schools in Census 2018\")\n",
    "censo17.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It's necessary drop duplicates whose are teachers in the same school but in different classes. \n",
    "#This way, the teacher appear just one time in each school. \n",
    "censo17.drop_duplicates(subset=['CO_PESSOA_FISICA', 'CO_ENTIDADE'], inplace=True)\n",
    "censo18.drop_duplicates(subset=['ID_DOCENTE', 'CO_ENTIDADE'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the schools represented in ENEM\n",
    "schoolsEnem17 = enem17.drop_duplicates('CO_ESCOLA')\n",
    "schoolsEnem17 = schoolsEnem17[(['CO_ESCOLA','TARGET'])]\n",
    "#schoolsEnem.astype('category', inplace=True)\n",
    "\n",
    "schoolsEnem18 = enem18.drop_duplicates('CO_ESCOLA')\n",
    "schoolsEnem18 = schoolsEnem18[(['CO_ESCOLA','TARGET'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the two datasets, whereas that only teachers who work in school represented in ENEM 17 and 18\n",
    "censo17= pd.merge(schoolsEnem17, censo17, left_on='CO_ESCOLA', right_on='CO_ENTIDADE', how='inner')\n",
    "\n",
    "censo18= pd.merge(schoolsEnem18, censo18, left_on='CO_ESCOLA', right_on='CO_ENTIDADE', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CO_ESCOLA                 0\n",
      "TARGET                    0\n",
      "NU_ANO_CENSO              0\n",
      "CO_PESSOA_FISICA          0\n",
      "IN_ESPECIALIZACAO    117764\n",
      "IN_MESTRADO          117764\n",
      "IN_DOUTORADO         117764\n",
      "CO_ENTIDADE               0\n",
      "dtype: int64\n",
      "CO_ESCOLA                0\n",
      "TARGET                   0\n",
      "NU_ANO_CENSO             0\n",
      "ID_DOCENTE               0\n",
      "IN_ESPECIALIZACAO    97672\n",
      "IN_MESTRADO          97672\n",
      "IN_DOUTORADO         97672\n",
      "CO_ENTIDADE              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(censo17.isnull().sum())\n",
    "print(censo18.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Missing values in these cases are \"0\" \n",
    "censo17['IN_ESPECIALIZACAO'].fillna(0.0, inplace=True)\n",
    "censo17['IN_MESTRADO'].fillna(0.0, inplace=True)\n",
    "censo17['IN_DOUTORADO'].fillna(0.0, inplace=True)\n",
    "\n",
    "censo18['IN_ESPECIALIZACAO'].fillna(0.0, inplace=True)\n",
    "censo18['IN_MESTRADO'].fillna(0.0, inplace=True)\n",
    "censo18['IN_DOUTORADO'].fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In database have different patterns to represent level of education. ex: Master has signed in two different ways, or marked in Master and Especialization or just in Master.\n",
    "def education_level(df):\n",
    "    if (df.IN_ESPECIALIZACAO==0.0) & (df.IN_MESTRADO==0.0) & (df.IN_DOUTORADO ==0.0):\n",
    "        #print(0)\n",
    "        df['TITULACAO']= 0\n",
    "    elif (df.IN_ESPECIALIZACAO==1.0) & (df.IN_MESTRADO==0.0) & (df.IN_DOUTORADO ==0.0):\n",
    "        #print(1)\n",
    "        df['TITULACAO']= 1\n",
    "    elif (df.IN_ESPECIALIZACAO==1.0) & (df.IN_MESTRADO==1.0) & (df.IN_DOUTORADO ==0.0):\n",
    "        #print(2)\n",
    "        df['TITULACAO']= 2\n",
    "    elif (df.IN_ESPECIALIZACAO==0.0) & (df.IN_MESTRADO==1.0) & (df.IN_DOUTORADO ==0.0):\n",
    "        #print(2)\n",
    "        df['TITULACAO']= 2\n",
    "    else:\n",
    "        #print(3)\n",
    "        df['TITULACAO']= 3  \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "censo17=censo17.apply(education_level, axis=1)\n",
    "\n",
    "censo18=censo18.apply(education_level, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We will transform the Categorical ENEM database features from student grain to school grain (Decision Grain).  Instead the pratical use of MODE, it will use the regression on the attribute distribution, having its histogram relative frequencies as input and the  decision level TARGET as output.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the dataframe with the relative frequencies and target. Ready to applying regeression\n",
    "def relative_frequencies(df, colum):\n",
    "    root = (['CO_ESCOLA', 'TARGET'])\n",
    "    df = df [root + [colum]]\n",
    "    df = pd.get_dummies(df, columns=[colum])\n",
    "    filter_col = [col for col in df if col.startswith(colum)]\n",
    "    print (filter_col)\n",
    "    for x in filter_col:            \n",
    "        df[x] = df.groupby(df['CO_ESCOLA'])[x].transform(sum)/ df.groupby(df['CO_ESCOLA'])[x].transform('count')\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR_student_to_school (df1, df2, columns):\n",
    "    #colum = (['Q001', 'Q002'])\n",
    "    result = pd.DataFrame()\n",
    "    for x in columns:\n",
    "        #print(df1[x])\n",
    "        temp = relative_frequencies(df1,df1[x].name)\n",
    "        temp.drop_duplicates('CO_ESCOLA', inplace=True)\n",
    "        temp = temp.loc[:, ~temp.columns.isin(['CO_ESCOLA'])]\n",
    "        temp_DATA = temp.loc[:, temp.columns != 'TARGET']\n",
    "        temp_TARGET = temp.loc[:, temp.columns == 'TARGET']\n",
    "        \n",
    "        LR_temp = LogisticRegression()\n",
    "        LR_temp.fit(temp_DATA, temp_TARGET)\n",
    "        print(\"Aprendi\")\n",
    "        \n",
    "        \n",
    "        temp = relative_frequencies(df2,df2[x].name)\n",
    "        temp.drop_duplicates('CO_ESCOLA', inplace=True) # v se funciona o inplace\n",
    "        temp = temp.loc[:, ~temp.columns.isin(['CO_ESCOLA'])]\n",
    "        temp_DATA = temp.loc[:, temp.columns != 'TARGET']\n",
    "        \n",
    "        result[x] =  LR_temp.predict_proba(temp_DATA)[:,1]\n",
    "        print(\"Apliquei\")\n",
    "       \n",
    "    result = pd.merge(result, df2.CO_ESCOLA, left_index=True, right_index=True)\n",
    "        \n",
    "    return result\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_enem = (['Q001', 'Q002'])\n",
    "trans_enem_att=LR_student_to_school(enem17, enem18, colum)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "category_censo = (['TITULACAO'])\n",
    "transform_censo_att=LR_student_to_school(censo17, censo18, colum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data0 = pd.merge(trans_enem_att,transform_censo_att, left_on='CO_ESCOLA', right_on='CO_ENTIDADE', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q001 = relative_frequencies(enem17, enem17.Q001.name)\n",
    "Q001 = Q001.drop_duplicates_trLR_Q001 = LogisticRegression()\n",
    "LR_Q001.fit(Q001_DATA, Q001_TARGET)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q002 = relative_frequencies(enem17, enem17.Q002.name)\n",
    "Q002 = Q002.drop_duplicates('CO_ESCOLA')\n",
    "Q002 = Q002.loc[:, ~Q002.columns.isin(['CO_ESCOLA'])]\n",
    "Q002_DATA = Q002.loc[:, Q002.columns != 'TARGET']\n",
    "Q002_TARGET = Q002.loc[:, Q002.columns == 'TARGET']\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LR_Q002 = LogisticRegression()\n",
    "LR_Q002.fit(Q002_DATA,Q002_TARGET)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TITULACAO = relative_frequencies(censo17, censo17.TITULACAO.name)\n",
    "TITULACAO = TITULACAO.drop_duplicates('CO_ESCOLA')\n",
    "TITULACAO = TITULACAO.loc[:, ~TITULACAO.columns.isin(['CO_ESCOLA'])]\n",
    "TITULACAO_DATA =TITULACAO.loc[:, TITULACAO.columns != 'TARGET']\n",
    "TITULACAO_TARGET = TITULACAO.loc[:, TITULACAO.columns == 'TARGET']\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LR_TITULACAO = LogisticRegression()\n",
    "LR_TITULACAO.fit(TITULACAO_DATA, TITULACAO_TARGET)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_Q002.predict_proba(Q002_DATA)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
